{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2509c026-aa65-4e85-a74b-677d26cd4ce0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1b70b2-8304-4558-bab3-36afdd071718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import time\n",
    "import os\n",
    "\n",
    "import open3d as o3d\n",
    "import trimesh\n",
    "\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "from skimage.measure import marching_cubes\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e75fec7-2139-4028-9e27-b5909cd7d5ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0c6c2c-0792-450a-8bba-7c56d8ecc9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Flip Y axis on voxel-based coords ===\n",
    "def flip_y_axis(coords):\n",
    "    y = coords[:, 1]\n",
    "    y_min, y_max = y.min(), y.max()\n",
    "    coords[:, 1] = y_max - (y - y_min)\n",
    "    return coords\n",
    "\n",
    "# === Utilities ===\n",
    "def normalize_preserve_aspect_align_y(pts):\n",
    "    min_val = pts.min(0)\n",
    "    max_val = pts.max(0)\n",
    "    size = max_val - min_val\n",
    "    scale = size.max()\n",
    "    norm = (pts - min_val) / (scale + 1e-8)\n",
    "    norm[:, 1] -= norm[:, 1].max()\n",
    "    return norm\n",
    "\n",
    "\n",
    "def compute_metrics(name, full_pts, ref_pts, grid_size=128):\n",
    "    volume = ConvexHull(full_pts).volume\n",
    "    density = len(full_pts) / volume\n",
    "    voxel_iou = voxel_iou_unit_cube(full_pts, ref_pts, grid_size)\n",
    "    return volume, density, voxel_iou\n",
    "\n",
    "\n",
    "def make_trace(pts, color, name):\n",
    "    return go.Scatter3d(\n",
    "        x=pts[:, 0], y=pts[:, 1], z=pts[:, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(size=1.5, color=color),\n",
    "        name=name\n",
    "    )\n",
    "\n",
    "def convex_hull_trace(pts, name, color, opacity=0.3):\n",
    "    hull = ConvexHull(pts)\n",
    "    simplices = hull.simplices\n",
    "    i, j, k = simplices[:, 0], simplices[:, 1], simplices[:, 2]\n",
    "    return go.Mesh3d(\n",
    "        x=pts[:, 0], y=pts[:, 1], z=pts[:, 2],\n",
    "        i=i, j=j, k=k,\n",
    "        name=f\"{name} Hull\",\n",
    "        opacity=opacity,\n",
    "        color=color,\n",
    "        flatshading=True,\n",
    "        showscale=False\n",
    "    )\n",
    "\n",
    "def voxelize_unit_cube(points, grid_size=128):\n",
    "    pts = np.clip(points, 0.0, 1.0)\n",
    "    vox = (pts * (grid_size - 1)).astype(np.int32)\n",
    "    return set(map(tuple, vox))\n",
    "\n",
    "def voxel_iou_unit_cube(points, ref_points, grid_size=128):\n",
    "    vox_a = voxelize_unit_cube(points, grid_size)\n",
    "    vox_b = voxelize_unit_cube(ref_points, grid_size)\n",
    "\n",
    "    if len(vox_a) == 0 and len(vox_b) == 0:\n",
    "        return 1.0\n",
    "    if len(vox_a) == 0 or len(vox_b) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return len(vox_a & vox_b) / len(vox_a | vox_b)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e4ac72-3d3d-44d7-8987-54797e20f6a0",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a677ab-9222-439c-b9af-32a35e85f292",
   "metadata": {},
   "source": [
    "#### Load sparse (SfM), dense (MVS), and apply 4-way symmetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b2d42f-3965-408a-9858-fbb4893f8ea3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# === Timer + Counters ===\n",
    "step_times = {}\n",
    "point_counts = {}\n",
    "def time_step(label):\n",
    "    global t0\n",
    "    t1 = time.time()\n",
    "    if 't0' in globals():\n",
    "        step_times[label] = t1 - t0\n",
    "    t0 = t1\n",
    "def count_points(label, pts):\n",
    "    point_counts[label] = len(pts)\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# === Step 1: Load Sparse and Dense Point Clouds ===\n",
    "root_path = os.getcwd()\n",
    "\n",
    "sparse_path = os.path.join(\n",
    "    root_path, \"results/4.Inter-method_3D\", \"segmented_point_cloud_final.ply\"\n",
    ")\n",
    "dense_path = os.path.join(\n",
    "    root_path, \"results/4.Inter-method_3D\", \"fused.ply\"\n",
    ")\n",
    "\n",
    "pcd_sparse = o3d.io.read_point_cloud(sparse_path)\n",
    "pcd_dense = o3d.io.read_point_cloud(dense_path)\n",
    "pts_sparse = np.asarray(pcd_sparse.points)\n",
    "colors_sparse = (np.asarray(pcd_sparse.colors) * 255).astype(np.uint8)\n",
    "pts_dense = np.asarray(pcd_dense.points)\n",
    "colors_dense = (np.asarray(pcd_dense.colors) * 255).astype(np.uint8)\n",
    "count_points(\"Sparse\", pts_sparse)\n",
    "count_points(\"Dense\", pts_dense)\n",
    "time_step(\"Load Point Clouds\")\n",
    "\n",
    "# === Step 2: Visualize Helper ===\n",
    "def visualize_point_cloud(pts, cols, title, sample=10000):\n",
    "    idx = np.random.choice(len(pts), min(sample, len(pts)), replace=False)\n",
    "    rgb = ['rgb({},{},{})'.format(*c) for c in cols[idx]]\n",
    "    trace = go.Scatter3d(x=pts[idx][:,0], y=pts[idx][:,1], z=pts[idx][:,2],\n",
    "                         mode='markers', marker=dict(size=1, color=rgb), name=title)\n",
    "    fig = go.Figure(data=[trace])\n",
    "    fig.update_layout(title=title, scene=dict(aspectmode='data'),\n",
    "                      width=1000, height=800)\n",
    "    fig.show()\n",
    "time_step(\"Define Visualization Helper\")\n",
    "\n",
    "# === Step 3: Crop Dense by Sparse Bounding Box ===\n",
    "bbox_min, bbox_max = pts_sparse.min(0), pts_sparse.max(0)\n",
    "mask_crop_bbox = np.all((pts_dense >= bbox_min) & (pts_dense <= bbox_max), axis=1)\n",
    "time_step(\"Crop Dense to Sparse BBox\")\n",
    "\n",
    "# === Step 4: Detect Bright Color Noise ===\n",
    "bright_mask = (colors_dense[:,0] > 200) & (colors_dense[:,1] > 200) & (colors_dense[:,2] > 200)\n",
    "combined_mask = mask_crop_bbox & bright_mask\n",
    "pts_bright_noise = pts_dense[combined_mask]\n",
    "cols_bright_noise = colors_dense[combined_mask]\n",
    "visualize_point_cloud(pts_bright_noise, cols_bright_noise, \"Bright-Colored Noise Points\")\n",
    "count_points(\"Bright Noise\", pts_bright_noise)\n",
    "time_step(\"Detect Bright Noise\")\n",
    "\n",
    "# === Step 5: Filter Out Bright Noise ===\n",
    "valid_mask = mask_crop_bbox & ~bright_mask\n",
    "pts_crop = pts_dense[valid_mask]\n",
    "cols_crop = colors_dense[valid_mask]\n",
    "visualize_point_cloud(pts_crop, cols_crop, \"Filtered Dense Crop\")\n",
    "count_points(\"Filtered Crop\", pts_crop)\n",
    "time_step(\"Filter Dense by Color\")\n",
    "\n",
    "# === Step 6: Detect Orange Facade in Sparse ===\n",
    "orange = np.array([255,127,14])\n",
    "z_min, z_max = 10.5, 10.7\n",
    "facade_mask = (np.all(colors_sparse == orange, axis=1)) & (pts_sparse[:,2] >= z_min) & (pts_sparse[:,2] <= z_max)\n",
    "pts_facade_sparse = pts_sparse[facade_mask]\n",
    "facade_min, facade_max = pts_facade_sparse.min(0), pts_facade_sparse.max(0)\n",
    "count_points(\"Facade (Sparse)\", pts_facade_sparse)\n",
    "time_step(\"Detect Orange Facade\")\n",
    "\n",
    "# === Step 7: Crop Dense by Facade BBox ===\n",
    "mask_facade_dense = np.all((pts_crop >= facade_min) & (pts_crop <= facade_max), axis=1)\n",
    "pts_facade_dense = pts_crop[mask_facade_dense]\n",
    "count_points(\"Facade (Dense)\", pts_facade_dense)\n",
    "time_step(\"Crop Dense Facade Region\")\n",
    "\n",
    "# === Step 8: Fit Plane and Align to Z+ ===\n",
    "pcd_facade = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(pts_facade_dense))\n",
    "plane_model, _ = pcd_facade.segment_plane(0.01, 3, 1000)\n",
    "a, b, c, d = plane_model\n",
    "normal = np.array([a, b, c]) / np.linalg.norm([a, b, c])\n",
    "target = np.array([0, 0, 1])\n",
    "v = np.cross(normal, target)\n",
    "s = np.linalg.norm(v)\n",
    "c = np.dot(normal, target)\n",
    "vx = np.array([[0, -v[2], v[1]], [v[2], 0, -v[0]], [-v[1], v[0], 0]])\n",
    "R_align = np.eye(3) if s < 1e-8 else np.eye(3) + vx + vx @ vx * ((1 - c) / (s**2))\n",
    "print(\"=== R_align (Facade to Z+): ===\\n\", R_align)\n",
    "pts_rot = (R_align @ pts_crop.T).T\n",
    "cols_rot = cols_crop\n",
    "visualize_point_cloud(pts_rot, cols_rot, \"Aligned Dense Crop\")\n",
    "count_points(\"Aligned Crop\", pts_rot)\n",
    "time_step(\"Align Facade to Z+\")\n",
    "\n",
    "# === Step 9: Naive 4-Way Symmetry ===\n",
    "x_mid = (pts_rot[:,0].min() + pts_rot[:,0].max()) / 2\n",
    "y_mid = (pts_rot[:,1].min() + pts_rot[:,1].max()) / 2\n",
    "z_mid = (pts_rot[:,2].min() + pts_rot[:,2].max()) / 2\n",
    "center = np.array([x_mid, y_mid, z_mid])\n",
    "R_y90  = np.array([[ 0, 0, -1],[ 0, 1,  0],[ 1, 0,  0]])\n",
    "R_y_90 = np.array([[ 0, 0,  1],[ 0, 1,  0],[-1, 0,  0]])\n",
    "def spin(pts, R): return (R @ (pts - center).T).T + center\n",
    "P_front = pts_rot.copy()\n",
    "P_back  = pts_rot.copy(); P_back[:,2] = 2*z_mid - P_back[:,2]\n",
    "P_left  = spin(pts_rot, R_y90);  P_left[:,0] = 2*x_mid - P_left[:,0]\n",
    "P_right = spin(pts_rot, R_y_90); P_right[:,0] = 2*x_mid - P_right[:,0]\n",
    "visualize_point_cloud(np.vstack([P_front, P_back, P_left, P_right]),\n",
    "                      np.tile(cols_rot, (4, 1)), \"Naive Symmetric Cloud\")\n",
    "time_step(\"Generate Naive Symmetry\")\n",
    "\n",
    "# === Step 10: ICP Alignment + Comparison ===\n",
    "def make_o3d_pcd(pts, colors):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(pts)\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors / 255.0)\n",
    "    pcd.estimate_normals()\n",
    "    return pcd\n",
    "def icp_align(source_pts, source_cols, target_pts, target_cols, max_dist=0.05):\n",
    "    pcd_src = make_o3d_pcd(source_pts, source_cols)\n",
    "    pcd_tgt = make_o3d_pcd(target_pts, target_cols)\n",
    "    reg = o3d.pipelines.registration.registration_icp(\n",
    "        pcd_src, pcd_tgt, max_dist, np.eye(4),\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint()\n",
    "    )\n",
    "    aligned = np.asarray(pcd_src.transform(reg.transformation).points)\n",
    "    return aligned, reg.transformation\n",
    "def compare_icp(before, after, label):\n",
    "    diff = np.linalg.norm(before - after, axis=1)\n",
    "    print(f\"{label} ICP Δ: Mean={np.mean(diff):.6f}, Max={np.max(diff):.6f}, Std={np.std(diff):.6f}, Shifted={(diff > 1e-4).sum()}/{len(diff)}\")\n",
    "\n",
    "P_left_aligned,  T_left  = icp_align(P_left,  cols_rot, P_front, cols_rot)\n",
    "P_right_aligned, T_right = icp_align(P_right, cols_rot, P_front, cols_rot)\n",
    "P_back_aligned,  T_back  = icp_align(P_back,  cols_rot, P_left_aligned, cols_rot)\n",
    "\n",
    "print(\"\\n=== ICP Transformation Matrices ===\")\n",
    "print(\"T_left:\\n\", T_left)\n",
    "print(\"T_right:\\n\", T_right)\n",
    "print(\"T_back:\\n\", T_back)\n",
    "\n",
    "compare_icp(P_left,  P_left_aligned,  \"Left\")\n",
    "compare_icp(P_right, P_right_aligned, \"Right\")\n",
    "compare_icp(P_back,  P_back_aligned,  \"Back\")\n",
    "time_step(\"ICP Alignment\")\n",
    "\n",
    "# === Step 11: Final Stack and Visualization ===\n",
    "all_pts = np.vstack([P_front, P_left_aligned, P_right_aligned, P_back_aligned])\n",
    "all_cols = np.tile(cols_rot, (4, 1))\n",
    "count_points(\"Final ICP Cloud\", all_pts)\n",
    "visualize_point_cloud(all_pts, all_cols, \"ICP-Aligned Symmetric Cloud\")\n",
    "time_step(\"Stack + Visualize Final Cloud\")\n",
    "\n",
    "# === Step 12: Print Summary ===\n",
    "print(\"\\n=== Runtime Summary ===\")\n",
    "for step, secs in step_times.items():\n",
    "    print(f\"{step:<40}: {secs:.3f} s\")\n",
    "\n",
    "print(\"\\n=== Point Counts ===\")\n",
    "for step, count in point_counts.items():\n",
    "    print(f\"{step:<30}: {count} points\")\n",
    "\n",
    "# === Align completed cloud to sparse Y-level ===\n",
    "y_ref = pts_sparse[:, 1].min()\n",
    "y_all = all_pts[:, 1].min()\n",
    "dy = y_ref - y_all\n",
    "all_pts_aligned = all_pts.copy()\n",
    "all_pts_aligned[:, 1] += dy\n",
    "\n",
    "# === Crop dense cloud to sparse bbox ===\n",
    "bbox_min = pts_sparse.min(0)\n",
    "bbox_max = pts_sparse.max(0)\n",
    "mask_dense_crop = np.all((pts_dense >= bbox_min) & (pts_dense <= bbox_max), axis=1)\n",
    "pts_dense_crop = pts_dense[mask_dense_crop]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c19d1e-6a6b-4a52-838b-d094681a9702",
   "metadata": {},
   "source": [
    "#### Load voxel (proposed) and synthetic (CAD) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bafed1-06a1-4ce4-9894-a5167298ce06",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load voxel data ###\n",
    "\n",
    "carved_data = np.load( os.path.join(\n",
    "    root_path, \"results/4.Inter-method_3D\", \"Taj_voxel_grid.npz\"))\n",
    "carved_mask = np.any(carved_data[\"voxel_grid\"] != 0, axis=-1)\n",
    "carved_coords = np.array(np.nonzero(carved_mask)).T.astype(np.float32)\n",
    "carved_coords = flip_y_axis(carved_coords)\n",
    "\n",
    "# =========================================================\n",
    "#  Load Synthetic Taj Mesh\n",
    "# =========================================================\n",
    "scene = trimesh.load(os.path.join(\n",
    "    root_path, \"results/4.Inter-method_3D/synthetic_taj.obj\"), force='scene')\n",
    "\n",
    "if isinstance(scene, trimesh.Scene):\n",
    "    combined_mesh = trimesh.util.concatenate([scene.geometry[name] for name in scene.geometry])\n",
    "else:\n",
    "    combined_mesh = scene\n",
    "\n",
    "# Swap Y/Z\n",
    "transformation_matrix = np.array([\n",
    "    [1,  0,  0],\n",
    "    [0,  0,  1],\n",
    "    [0,  1,  0]\n",
    "])\n",
    "transformed_vertices = combined_mesh.vertices @ transformation_matrix.T\n",
    "faces = combined_mesh.faces\n",
    "ref_mesh = trimesh.Trimesh(vertices=transformed_vertices, faces=faces)\n",
    "\n",
    "# Sample points from synthetic mesh\n",
    "sampled_points = ref_mesh.sample(50000)\n",
    "transformed_vertices = flip_y_axis(transformed_vertices)\n",
    "sampled_points = flip_y_axis(sampled_points)\n",
    "\n",
    "ref_vertices_norm = normalize_preserve_aspect(transformed_vertices)\n",
    "sampled_points_norm = normalize_preserve_aspect(sampled_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69ae322-693c-44d4-820d-b78930b38bb0",
   "metadata": {},
   "source": [
    "### Convert to point cloud and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df579cf-275c-4669-a36c-1c5f06bf5ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Prepare point cloud dictionary ===\n",
    "data_dict = {\n",
    "    \"Sparse\": (pts_sparse, len(pts_sparse)),\n",
    "    \"Dense (Cropped)\": (pts_dense_crop, len(pts_dense_crop)),\n",
    "    \"Completed (ICP Aligned)\": (all_pts_aligned, len(all_pts_aligned)),\n",
    "    \"Carved Grid\": (carved_coords, len(carved_coords)),\n",
    "    \"Synthetic\" : (sampled_points, len(sampled_points))\n",
    "}\n",
    "\n",
    "# === Normalize clouds ===\n",
    "norm_data = {}\n",
    "for name, (pts, _) in data_dict.items():\n",
    "    norm_pts = normalize_preserve_aspect_align_y(pts)\n",
    "    norm_data[name] = norm_pts, len(pts)\n",
    "\n",
    "# === Plotting ===\n",
    "colors = ['blue', 'green', 'magenta', 'purple', 'yellow']\n",
    "combined_traces = []\n",
    "\n",
    "for (name, (pts_norm, _)), color in zip(norm_data.items(), colors):\n",
    "    pts_vis = pts_norm if len(pts_norm) < 10000 else pts_norm[np.random.choice(len(pts_norm), 10000, replace=False)]\n",
    "    pt_trace = make_trace(pts_vis, color, name)\n",
    "    hull_input = pts_norm if len(pts_norm) <= 5000 else pts_norm[np.random.choice(len(pts_norm), 5000, replace=False)]\n",
    "    hull_trace = convex_hull_trace(hull_input, name, color=color, opacity=0.3)\n",
    "    combined_traces.extend([pt_trace, hull_trace])\n",
    "\n",
    "# === Combined overlay plot ===\n",
    "combined_fig = go.Figure(data=combined_traces)\n",
    "combined_fig.update_layout(\n",
    "    title=\"All Point Clouds with Convex Hulls (Overlay)\",\n",
    "    scene=dict(\n",
    "        aspectmode='data',\n",
    "        xaxis_title='X', yaxis_title='Y', zaxis_title='Z'\n",
    "    ),\n",
    "    width=1000,\n",
    "    height=800,\n",
    "    showlegend=True\n",
    ")\n",
    "combined_fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ddb0a7-e525-4cd0-884d-84beb46a39bb",
   "metadata": {},
   "source": [
    "### Compute accuracy, completeness, and regularity on point clouds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d1562f-6845-426d-a40f-bdcc9ac9b618",
   "metadata": {},
   "source": [
    "#### accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e21d5b-2450-44f1-bb04-e55cdb224547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Metric Functions ===\n",
    "\n",
    "def chamfer_distance_l2(A, B):\n",
    "    nn_A = NearestNeighbors(n_neighbors=1, n_jobs=-1).fit(B)\n",
    "    d_A, _ = nn_A.kneighbors(A)\n",
    "    nn_B = NearestNeighbors(n_neighbors=1, n_jobs=-1).fit(A)\n",
    "    d_B, _ = nn_B.kneighbors(B)\n",
    "    return np.mean(d_A**2) + np.mean(d_B**2)\n",
    "\n",
    "def chamfer_distance_l1(A, B):\n",
    "    nn_A = NearestNeighbors(n_neighbors=1, n_jobs=-1).fit(B)\n",
    "    d_A, _ = nn_A.kneighbors(A)\n",
    "\n",
    "    nn_B = NearestNeighbors(n_neighbors=1, n_jobs=-1).fit(A)\n",
    "    d_B, _ = nn_B.kneighbors(B)\n",
    "\n",
    "    return np.mean(d_A) + np.mean(d_B)\n",
    "\n",
    "def f_score(A, B, threshold=0.01):\n",
    "    nn_A = NearestNeighbors(n_neighbors=1, n_jobs=-1).fit(B)\n",
    "    d_A, _ = nn_A.kneighbors(A)\n",
    "    nn_B = NearestNeighbors(n_neighbors=1, n_jobs=-1).fit(A)\n",
    "    d_B, _ = nn_B.kneighbors(B)\n",
    "    precision = np.mean(d_A[:, 0] < threshold)\n",
    "    recall = np.mean(d_B[:, 0] < threshold)\n",
    "    f = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "    return f, precision, recall\n",
    "\n",
    "def convex_iou(A, B):\n",
    "    try:\n",
    "        hull_A = ConvexHull(A)\n",
    "        hull_B = ConvexHull(B)\n",
    "        union = ConvexHull(np.vstack([A, B]))\n",
    "        inter_vol = hull_A.volume + hull_B.volume - union.volume\n",
    "        return inter_vol / union.volume\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def pca_shape_similarity(A, B):\n",
    "    pca_A = PCA(n_components=3).fit(A)\n",
    "    pca_B = PCA(n_components=3).fit(B)\n",
    "    return np.sum(np.abs(pca_A.explained_variance_ratio_ - pca_B.explained_variance_ratio_))\n",
    "\n",
    "def uniform_sample(P, n=50000):\n",
    "    if len(P) <= n:\n",
    "        return P\n",
    "    idx = np.random.choice(len(P), n, replace=False)\n",
    "    return P[idx]\n",
    "\n",
    "# =========================================================\n",
    "#  Accuracy Metrics (vs Synthetic)\n",
    "# =========================================================\n",
    "# =========================================================\n",
    "#  Accuracy Metrics (vs Synthetic) + Distance Cache\n",
    "# =========================================================\n",
    "\n",
    "accuracy_metrics = {}\n",
    "distance_cache = {}   # <-- ADD THIS\n",
    "\n",
    "ref_name = \"Synthetic\"\n",
    "ref_pts = norm_data[ref_name][0]\n",
    "ref_sample = uniform_sample(ref_pts, 50000)\n",
    "\n",
    "print(\"\\n=== Accuracy Metrics vs Synthetic ===\")\n",
    "\n",
    "for name, (pts, _) in norm_data.items():\n",
    "    if name == \"Synthetic\":\n",
    "        continue\n",
    "\n",
    "    print(f\"→ {name}\")\n",
    "\n",
    "    pts_sample = uniform_sample(pts, 50000)\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # NN distances (ONCE, reused everywhere)\n",
    "    # -----------------------------------------------------\n",
    "    nn_A = NearestNeighbors(n_neighbors=1, n_jobs=-1).fit(ref_sample)\n",
    "    d_A, _ = nn_A.kneighbors(pts_sample)\n",
    "\n",
    "    nn_B = NearestNeighbors(n_neighbors=1, n_jobs=-1).fit(pts_sample)\n",
    "    d_B, _ = nn_B.kneighbors(ref_sample)\n",
    "\n",
    "    d_AB = d_A[:, 0]\n",
    "    d_BA = d_B[:, 0]\n",
    "\n",
    "    distance_cache[name] = (d_AB, d_BA)   # <-- STORE\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Metrics (UNCHANGED)\n",
    "    # -----------------------------------------------------\n",
    "    chamfer_l2 = chamfer_distance_l2(pts_sample, ref_sample)\n",
    "    chamfer_l1 = chamfer_distance_l1(pts_sample, ref_sample)\n",
    "\n",
    "    f1, prec, rec = f_score(pts_sample, ref_sample, threshold=0.03)\n",
    "\n",
    "    pca_diff = pca_shape_similarity(pts_sample, ref_sample)\n",
    "    pca_sim  = 1.0 - pca_diff\n",
    "\n",
    "    iou = convex_iou(pts, ref_pts)\n",
    "\n",
    "    accuracy_metrics[name] = {\n",
    "        \"Chamfer L2 ↓\": chamfer_l2,\n",
    "        \"Chamfer L1 ↓\": chamfer_l1,\n",
    "        \"Precision ↑\": prec,\n",
    "        \"Recall ↑\": rec,\n",
    "        \"F1 score\": f1,\n",
    "        \"PCA Similarity ↑\": pca_sim,\n",
    "        \"Convex IoU ↑\": iou\n",
    "    }\n",
    "\n",
    "    print(\n",
    "        f\"  CD-L2={chamfer_l2:.4f}, \"\n",
    "        f\"CD-L1={chamfer_l1:.4f}, \"\n",
    "        f\"Prec={prec:.3f}, \"\n",
    "        f\"Rec={rec:.3f}, \"\n",
    "        f\"F1={f1:.3f}, \"\n",
    "        f\"PCA={pca_sim:.3f}, \"\n",
    "        f\"IoU={iou:.3f}\"\n",
    "    )\n",
    "\n",
    "df_acc = pd.DataFrame(accuracy_metrics).T\n",
    "df_acc = df_acc.applymap(lambda x: float(f\"{x:.6g}\"))\n",
    "\n",
    "print(\"\\n=== Accuracy Metrics Table ===\")\n",
    "print(df_acc.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095e8311-b2bc-4c6a-a342-d201b8eb4d48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f1_curve(d_AB, d_BA, thresholds):\n",
    "    f1s = []\n",
    "    for t in thresholds:\n",
    "        prec = np.mean(d_AB < t)\n",
    "        rec  = np.mean(d_BA < t)\n",
    "        f1   = 0.0 if (prec + rec) == 0 else 2 * prec * rec / (prec + rec)\n",
    "        f1s.append(f1)\n",
    "    return np.array(f1s)\n",
    "\n",
    "\n",
    "thresholds = np.linspace(0.0, 0.1, 40)\n",
    "\n",
    "fig = go.Figure()\n",
    "best_results = {}\n",
    "\n",
    "for name, (d_AB, d_BA) in distances.items():\n",
    "    f1 = f1_curve(d_AB, d_BA, thresholds)\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=thresholds,\n",
    "        y=f1,\n",
    "        mode=\"lines\",\n",
    "        name=name\n",
    "    ))\n",
    "\n",
    "    idx = np.argmax(f1)\n",
    "    best_results[name] = {\n",
    "        \"Best F1\": f1[idx],\n",
    "        \"Tau\": thresholds[idx]\n",
    "    }\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"F1 vs Threshold (τ)\",\n",
    "    xaxis_title=\"Threshold τ\",\n",
    "    yaxis_title=\"F1\",\n",
    "    width=900,\n",
    "    height=600\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "print(pd.DataFrame(best_results).round(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1705400-4aa1-43f1-8ce8-5a694a784825",
   "metadata": {},
   "source": [
    "#### completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a110d2-08ad-4857-b28a-6baca6e258d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Compute metrics w.r.t. Synthetic ===\n",
    "metrics = {}\n",
    "\n",
    "ref_name = \"Synthetic\"\n",
    "ref_pts = norm_data[ref_name][0]\n",
    "\n",
    "for name, (pts, _) in norm_data.items():\n",
    "    vol, dens, iou = compute_metrics(\n",
    "        name,\n",
    "        pts,\n",
    "        ref_pts=ref_pts,\n",
    "        grid_size=128\n",
    "    )\n",
    "    metrics[name] = [vol, dens, iou]\n",
    "\n",
    "# === Format and display table ===\n",
    "results = {\n",
    "    \"Metric\": [\n",
    "        \"Convex Volume (normalized unit³)\",\n",
    "        \"Point Density (pts/unit³)\",\n",
    "        \"Voxel IoU (w.r.t. Synthetic)\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "for name in norm_data.keys():\n",
    "    vol, dens, iou = metrics[name]\n",
    "    results[name] = [vol, dens, iou]\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "pd.set_option('display.precision', 3)\n",
    "\n",
    "df_formatted = df.applymap(\n",
    "    lambda x: \"\" if pd.isna(x) else f\"{x:,.3f}\" if isinstance(x, float) else str(x)\n",
    ")\n",
    "\n",
    "print(df_formatted.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6155826e-efb5-466c-afc5-fc313d9437de",
   "metadata": {},
   "source": [
    "#### regularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520b213d-e48c-48f9-986d-05760ca90ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Nearest-neighbor regularity metric\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def compute_nn_stats(pts, max_points=50000):\n",
    "    # Subsample for speed (same as earlier)\n",
    "    if len(pts) > max_points:\n",
    "        idx = np.random.choice(len(pts), max_points, replace=False)\n",
    "        pts = pts[idx]\n",
    "\n",
    "    nbrs = NearestNeighbors(n_neighbors=2, n_jobs=-1).fit(pts)\n",
    "    distances, _ = nbrs.kneighbors(pts)\n",
    "\n",
    "    nn = distances[:, 1]  # exclude self\n",
    "    return {\n",
    "        \"NN Mean ↓\": nn.mean(),\n",
    "        \"NN Std ↓\": nn.std(),\n",
    "        \"NN CV ↓\": nn.std() / (nn.mean() + 1e-8)\n",
    "    }\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Run regularity on normalized point clouds\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "regularity_metrics = {}\n",
    "\n",
    "cloud_order = [\n",
    "    \"Sparse\",\n",
    "    \"Dense (Cropped)\",\n",
    "    \"Completed (ICP Aligned)\",\n",
    "    \"Carved Grid\",\n",
    "]\n",
    "\n",
    "print(\"\\n=== Regularity Metrics (Nearest Neighbor Statistics) ===\")\n",
    "\n",
    "for name in cloud_order:\n",
    "    pts = norm_data[name][0]\n",
    "\n",
    "    # IMPORTANT: same orientation rule as everywhere else\n",
    "    if name == \"Carved Grid\":\n",
    "        pts = flip_y_axis(pts.copy())\n",
    "\n",
    "    stats = compute_nn_stats(pts)\n",
    "    regularity_metrics[name] = stats\n",
    "\n",
    "    print(\n",
    "        f\"{name:<25} | \"\n",
    "        f\"Mean={stats['NN Mean ↓']:.6f}, \"\n",
    "        f\"Std={stats['NN Std ↓']:.6f}, \"\n",
    "        f\"CV={stats['NN CV ↓']:.4f}\"\n",
    "    )\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Table (paper-ready)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "df_reg = pd.DataFrame(regularity_metrics).T\n",
    "df_reg = df_reg.applymap(lambda x: float(f\"{x:.6g}\"))\n",
    "\n",
    "print(\"\\n=== Regularity Metrics Table ===\")\n",
    "print(df_reg.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85763ad4-b37f-4648-8824-360a083c617c",
   "metadata": {},
   "source": [
    "### Compute smoothness on mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb6874d-5f1d-40f3-aec3-ca73ac96f7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "#  Mesh Extraction + Visualization + Surface Smoothness\n",
    "#  (Correct orientation + Synthetic mesh included)\n",
    "# =========================================================\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Utilities\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def normalize_preserve_aspect(points):\n",
    "    min_val = points.min(0)\n",
    "    max_val = points.max(0)\n",
    "    size = max_val - min_val\n",
    "    scale = size.max()\n",
    "    return (points - min_val) / (scale + 1e-8)\n",
    "\n",
    "def flip_y_axis(coords):\n",
    "    y = coords[:, 1]\n",
    "    y_min, y_max = y.min(), y.max()\n",
    "    coords[:, 1] = y_max - (y - y_min)\n",
    "    return coords\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Point cloud → voxel grid → marching cubes\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def pointcloud_to_voxel_grid(points, grid_size=128, sigma=1.0):\n",
    "    # CRITICAL: normalize here for voxelization\n",
    "    norm_points = normalize_preserve_aspect(points)\n",
    "\n",
    "    voxel_coords = (norm_points * (grid_size - 1)).astype(int)\n",
    "    grid = np.zeros((grid_size, grid_size, grid_size), dtype=np.float32)\n",
    "\n",
    "    for x, y, z in voxel_coords:\n",
    "        grid[x, y, z] += 1.0\n",
    "\n",
    "    return gaussian_filter(grid, sigma=sigma)\n",
    "\n",
    "def get_marching_cubes_mesh(points, grid_size=128, sigma=1.0, level=0.1):\n",
    "    voxel_grid = pointcloud_to_voxel_grid(points, grid_size, sigma)\n",
    "    verts, faces, _, _ = marching_cubes(voxel_grid, level=level)\n",
    "\n",
    "    # back to unit cube\n",
    "    verts /= grid_size\n",
    "    return verts, faces\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Surface metric helpers\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def compute_triangle_normals(vertices, faces):\n",
    "    v0 = vertices[faces[:, 0]]\n",
    "    v1 = vertices[faces[:, 1]]\n",
    "    v2 = vertices[faces[:, 2]]\n",
    "    normals = np.cross(v1 - v0, v2 - v0)\n",
    "    return normals / (np.linalg.norm(normals, axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "def compute_vertex_normals(vertices, faces):\n",
    "    tri_normals = compute_triangle_normals(vertices, faces)\n",
    "    vertex_normals = np.zeros_like(vertices)\n",
    "\n",
    "    for i in range(faces.shape[0]):\n",
    "        for j in range(3):\n",
    "            vertex_normals[faces[i, j]] += tri_normals[i]\n",
    "\n",
    "    return vertex_normals / (np.linalg.norm(vertex_normals, axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "def compute_surface_metrics(vertices, faces, k=20):\n",
    "    normals = compute_vertex_normals(vertices, faces)\n",
    "    nbrs = NearestNeighbors(n_neighbors=k).fit(vertices)\n",
    "    _, indices = nbrs.kneighbors(vertices)\n",
    "\n",
    "    normal_stds = []\n",
    "    roughness_vals = []\n",
    "    mean_curvatures = []\n",
    "    laplace_magnitudes = []\n",
    "\n",
    "    for i, nbr_idx in enumerate(indices):\n",
    "        nbr_pts = vertices[nbr_idx]\n",
    "        center = vertices[i]\n",
    "        center_normal = normals[i]\n",
    "\n",
    "        nbr_normals = normals[nbr_idx]\n",
    "        dot = np.clip(nbr_normals @ center_normal, -1.0, 1.0)\n",
    "        angles = np.degrees(np.arccos(dot))\n",
    "        normal_stds.append(np.std(angles))\n",
    "\n",
    "        pca = PCA(n_components=3).fit(nbr_pts)\n",
    "        roughness_vals.append(pca.explained_variance_[2])\n",
    "\n",
    "        laplace = nbr_pts.mean(axis=0) - center\n",
    "        laplace_magnitudes.append(np.linalg.norm(laplace))\n",
    "        mean_curvatures.append(np.linalg.norm(laplace))\n",
    "\n",
    "    return {\n",
    "        \"Normal StdDev (°)\": np.mean(normal_stds),\n",
    "        \"Mean Roughness (λ₃)\": np.mean(roughness_vals),\n",
    "        \"Mean Curvature\": np.mean(mean_curvatures),\n",
    "        \"Total Curvature\": np.sum(np.abs(mean_curvatures)),\n",
    "        \"Laplacian Smoothness\": np.mean(laplace_magnitudes)\n",
    "    }\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Plotly mesh\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def plot_mesh(vertices, faces, name, color, opacity=0.5):\n",
    "    i, j, k = faces[:, 0], faces[:, 1], faces[:, 2]\n",
    "    return go.Mesh3d(\n",
    "        x=vertices[:, 0],\n",
    "        y=vertices[:, 1],\n",
    "        z=vertices[:, 2],\n",
    "        i=i, j=j, k=k,\n",
    "        color=color,\n",
    "        opacity=opacity,\n",
    "        flatshading=True,\n",
    "        name=name,\n",
    "        showscale=False\n",
    "    )\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Run on norm_data\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "cloud_order = [\n",
    "    \"Sparse\",\n",
    "    \"Dense (Cropped)\",\n",
    "    \"Completed (ICP Aligned)\",\n",
    "    \"Carved Grid\",\n",
    "    \"Synthetic\"\n",
    "]\n",
    "\n",
    "colors = {\n",
    "    \"Sparse\": \"blue\",\n",
    "    \"Dense (Cropped)\": \"green\",\n",
    "    \"Completed (ICP Aligned)\": \"magenta\",\n",
    "    \"Carved Grid\": \"purple\",\n",
    "    \"Synthetic\": \"yellow\"\n",
    "}\n",
    "\n",
    "mesh_traces = []\n",
    "surface_metrics = {}\n",
    "\n",
    "for name in cloud_order:\n",
    "    pts = norm_data[name][0]\n",
    "\n",
    "    # FIX 1: flip only Carved Grid\n",
    "    if name == \"Carved Grid\":\n",
    "        pts = flip_y_axis(pts.copy())\n",
    "\n",
    "    print(f\"Processing: {name}\")\n",
    "\n",
    "    verts, faces = get_marching_cubes_mesh(\n",
    "        pts.astype(np.float32),\n",
    "        grid_size=128,\n",
    "        sigma=1.0\n",
    "    )\n",
    "\n",
    "    mesh_traces.append(\n",
    "        plot_mesh(\n",
    "            verts,\n",
    "            faces,\n",
    "            name,\n",
    "            colors[name],\n",
    "            opacity=0.35 if name == \"Synthetic\" else 0.5\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Do NOT compute smoothness for Synthetic if you don’t want\n",
    "    if name != \"Synthetic\":\n",
    "        surface_metrics[name] = compute_surface_metrics(verts, faces, k=20)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Visualize meshes\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "fig = go.Figure(data=mesh_traces)\n",
    "fig.update_layout(\n",
    "    title=\"Marching Cubes Meshes (Correct Orientation + Synthetic Reference)\",\n",
    "    scene=dict(aspectmode=\"data\"),\n",
    "    width=1200,\n",
    "    height=900,\n",
    "    showlegend=True\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Surface smoothness table\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "df_surface = pd.DataFrame(surface_metrics).T\n",
    "df_surface = df_surface.applymap(lambda x: f\"{x:.6f}\")\n",
    "\n",
    "print(\"\\n=== Surface Smoothness Metrics ===\")\n",
    "print(df_surface.to_string())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
